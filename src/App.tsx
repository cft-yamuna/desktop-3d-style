import { useState } from 'react';
import { GoogleGenAI } from '@google/genai';
import StartScreen from './components/StartScreen';
import CaptureScreen from './components/CaptureScreen';
import PreviewScreen from './components/PreviewScreen';
import ProcessingScreen from './components/ProcessingScreen';
import OutputScreen from './components/OutputScreen';
import { supabase } from './lib/supabase';
import type { Screen } from './types';

const ai = new GoogleGenAI({
  apiKey: import.meta.env.VITE_GEMINI_API_KEY,
});

function App() {
  const [currentScreen, setCurrentScreen] = useState<Screen>('start');
  const [capturedImage, setCapturedImage] = useState<string>('');
  const [imageUrl, setImageUrl] = useState<string>('');
  const [generatedImageUrl, setGeneratedImageUrl] = useState<string>('');
  const [analysisResult, setAnalysisResult] = useState<string>('');

  const handleStart = () => {
    setCurrentScreen('capture');
  };

  const handleCapture = (imageDataUrl: string) => {
    setCapturedImage(imageDataUrl);
    setCurrentScreen('preview');
  };

  const handleRetake = () => {
    setCapturedImage('');
    setCurrentScreen('capture');
  };

  const handleSubmit = async () => {
    setCurrentScreen('processing');

    const figurinePrompt = `Generate the output image in PORTRAIT orientation (2:3 aspect ratio, taller than wide).

In a realistic setting, a single figurine is placed on a computer desk. The figurine stands on a round, clear acrylic base without any text. The computer screen displays the 3D modeling process of this figurine. Beside the monitor sits a toy packaging box, styled like premium collectible figure packaging, decorated with original artwork. The box design features flat 2D illustrations.

Generate a figurine that looks EXACTLY like the person in this photo - same face, features, hair, and clothing. The figurine must be instantly recognizable as this specific person.

IMPORTANT: The output image MUST be in PORTRAIT orientation (vertical, taller than wide, 2:3 ratio).`;

    try {
      // Get base64 from captured image
      const base64Image = capturedImage.split(',')[1];

      // Use Google GenAI SDK with gemini-3-pro-image-preview model
      const contents = [
        {
          role: 'user' as const,
          parts: [
            {
              inlineData: {
                mimeType: 'image/jpeg',
                data: base64Image,
              },
            },
            {
              text: figurinePrompt,
            },
          ],
        },
      ];

      console.log('Calling Gemini API with gemini-3-pro-image-preview model...');

      const response = await ai.models.generateContentStream({
        model: 'gemini-3-pro-image-preview',
        config: {
          responseModalities: ['IMAGE', 'TEXT'],
        },
        contents,
      });

      let generatedImageBase64 = '';
      let generatedImageMimeType = 'image/png';
      let geminiResult = '';

      // Process streaming response
      for await (const chunk of response) {
        if (!chunk.candidates || !chunk.candidates[0]?.content?.parts) {
          continue;
        }

        for (const part of chunk.candidates[0].content.parts) {
          if (part.inlineData) {
            generatedImageBase64 = part.inlineData.data || '';
            generatedImageMimeType = part.inlineData.mimeType || 'image/png';
            console.log('Received image from Gemini');
          } else if (part.text) {
            geminiResult += part.text;
            console.log('Received text:', part.text);
          }
        }
      }

      if (!generatedImageBase64) {
        console.error('No image in response');
        throw new Error('No image was generated by Gemini.');
      }

      // Upload captured image to Supabase storage
      const capturedBlob = await (await fetch(capturedImage)).blob();
      const capturedFileName = `capture-${Date.now()}.jpg`;

      const { data: capturedUploadData, error: capturedUploadError } = await supabase.storage
        .from('cabphonepay')
        .upload(capturedFileName, capturedBlob, {
          contentType: 'image/jpeg',
          cacheControl: '3600',
        });

      if (capturedUploadError) throw capturedUploadError;

      const { data: { publicUrl: capturedPublicUrl } } = supabase.storage
        .from('cabphonepay')
        .getPublicUrl(capturedUploadData.path);

      // Convert generated image base64 to blob and upload
      const generatedImageBytes = Uint8Array.from(atob(generatedImageBase64), c => c.charCodeAt(0));
      const generatedBlob = new Blob([generatedImageBytes], { type: generatedImageMimeType });
      const generatedFileName = `generated-${Date.now()}.png`;

      const { data: generatedUploadData, error: generatedUploadError } = await supabase.storage
        .from('cabphonepay')
        .upload(generatedFileName, generatedBlob, {
          contentType: generatedImageMimeType,
          cacheControl: '3600',
        });

      if (generatedUploadError) throw generatedUploadError;

      const { data: { publicUrl: generatedPublicUrl } } = supabase.storage
        .from('cabphonepay')
        .getPublicUrl(generatedUploadData.path);

      // Save to database
      const { error: insertError } = await supabase
        .from('cabphonepay')
        .insert({
          image_url: capturedPublicUrl,
          generated_image_url: generatedPublicUrl,
          gemini_result: geminiResult || 'Image generated successfully',
        });

      if (insertError) throw insertError;

      setImageUrl(capturedPublicUrl);
      setGeneratedImageUrl(generatedPublicUrl);
      setAnalysisResult(geminiResult || 'Image generated successfully');
      setCurrentScreen('output');
    } catch (error) {
      console.error('Error processing image:', error);
      alert('An error occurred while processing your image. Please try again.');
      setCurrentScreen('preview');
    }
  };

  const handleHome = () => {
    setCapturedImage('');
    setImageUrl('');
    setGeneratedImageUrl('');
    setAnalysisResult('');
    setCurrentScreen('start');
  };

  return (
    <>
      {currentScreen === 'start' && <StartScreen onStart={handleStart} />}
      {currentScreen === 'capture' && <CaptureScreen onCapture={handleCapture} />}
      {currentScreen === 'preview' && (
        <PreviewScreen
          imageDataUrl={capturedImage}
          onRetake={handleRetake}
          onSubmit={handleSubmit}
        />
      )}
      {currentScreen === 'processing' && <ProcessingScreen />}
      {currentScreen === 'output' && (
        <OutputScreen
          imageUrl={imageUrl}
          generatedImageUrl={generatedImageUrl}
          result={analysisResult}
          onHome={handleHome}
        />
      )}
    </>
  );
}

export default App;
